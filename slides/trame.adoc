== !

=== Récolte de metrics avec les profilers Java Flight Recorder et Async – 5 minutes

* démo : on passe le flux : ça plante
* comment on analyse ça ?
* petit cours théorique sur le profiling JFR/Async

=== Stream "module tri des courriers"

* abus des opérations terminales dans les Stream
* exemple avec stream, collectors, count => on renvoi des Stream plutôt que des List

=== Instanciations inutiles "module chiffrement des données"

* profiling intellij => dump mémoire en hprof => utilisation de JMC (bof à l'utilisation) => je connais un truc mieux Eclipse Memory Analyzer
* Constantes : regexp / datetimeformatter
* Map sheetnames où on utilise finalement que 3 données sur 300

=== Fin de la première semaine

* compteur jours / giga de ram
* récap des actions et gains

=== "module reporting"

* présentation du module : reporting sur les courriers depuis la base de données
* explication du code et lancement avec le Profiling => beaucoup de données et c'est long .... 
* hibernate show sql => beaucoup trop de requêtes sur les relations, alors qu'on n'utilise même pas les données!
* on a qu'à mettre du LAZY !
* pas possible ça peut faire péter la chaîne, y'a déjà eu un fix : fake historique git sur le LAZY / EAGER des relations de l'entité courrier
* ok, donc on ne peut pas non plus mettre de Fetch.Subselect dans l'entité courrier
* on ajoute donc des FETCH dans les relations de la @Query => MultipleBagFetchException => il faut remplacer les List par des Set dans l'entité courrier => impossible d'y toucher
* 

* stream renvoyé par le repo => ça ne fonctionne pas à cause des relations type List : il faut les passer en Set.
* cf https://docs.spring.io/spring-data/jpa/reference/repositories/query-methods-details.html#repositories.scrolling.guidance
* mise en place de pg_statements => beaucoup trop de relations sur l'entité courrier
* projection => on en a déjà sur le projet, regarde => ok mais ça ne fonctionne pas à cause des relations

=== Fin de la seconde semaine

* compteur jours / giga de ram
* pas de gains
* Récap

=== "module reporting"

* bon, on fork courrier
* on regarde le résultat => beaucoup de requêtes identiques
* mise en place de cache => attention, cycle de vie du composant / TTL ...
* on regarde le résultat => des requêtes s'exécutent avant même le lancement du composant
* hypersistence-utils => ok, requêtes à l'init de certains composants dans un jar core

=== Fin de la troisième semaine

* compteur jours / giga de ram
* récap des actions et gains
    
=== Conclusion et questions

* moins de GC === moins de temps

* piste d'amélio :
** observabilité
** test de perf

// prénom Wilson / Forrest Gump / Sully
// Da Vinci Code

